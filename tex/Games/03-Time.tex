\chapter{Games and Time}

So far we've looked just at games where each player makes just one move, and they make it simultaneously. That might not feel like most games that you know about. It isn't how we play, for instance, chess. Instead, most games involve players making multiple moves, and these moves taking place in time. Here is one simple such game. It's not very interesting; you won't have fun games nights playing it. But it is useful to study.

\begin{quote}
\gamelab{Five} 

There are two players, who we'll call $A$ and $B$. First $A$ moves, then $B$, then finally $A$ moves again. Each move involves announcing a number, 1 or 2. $A$ wins if after the three moves, the numbers announced sum to 5. $B$ wins otherwise. 
\end{quote}


\noindent This is a simple zero-sum game. The payoff is either 1 to $A$ and 0 to $B$, or 1 to $B$ and 0 to $A$. For simplicity, we'll describe this as $A$ winning or $B$ winning. We'll soon be interested in games with draws, which are a payoff of \nicefrac{1}{2} to each player. But for now we're looking at games that someone wins. 

Before we go on, it's worth thinking about how you would play this game from each player's perspective. The formal approach we'll eventually take is pretty similar, I think, to the way one thinks about the game.

%Some games take time
%The number 5 game

\section{Normal Form and Extensive Form}

Figure \ref{FiveGameChart} is the \textbf{extensive form} representation of \citegame{Five}. We will use $\mathpzc{W}$ to denote that $A$ wins, and $\mathpzc{L}$ to denote that $B$ wins. 

\begin{figure}[t]
\begin{center}
\begin{picture}(350, 150)
\pictext{175}{0}{$A$}
\put(175, 12){\circle{4}}\put(173, 13){\line(-2, 1){69}}
\put(177, 13){\line(2, 1){69}}
\pictext{135}{20}{1}
\pictext{215}{20}{2}

\pictext{105}{35}{$B$}
\put(105, 47){\circle*{4}}
\put(105, 47){\line(-1, 1){35}}
\put(105, 47){\line(1, 1){35}}
\pictext{80}{55}{1}
\pictext{130}{55}{2}

\pictext{245}{35}{$B$}
\put(245, 47){\circle*{4}}
\put(245, 47){\line(-1, 1){35}}
\put(245, 47){\line(1, 1){35}}
\pictext{220}{55}{1}
\pictext{270}{55}{2}

\pictext{70}{70}{$A$}
\put(70, 82){\circle*{4}}
\put(70, 82){\line(-1, 2){20}}
\pictext{50}{125}{$\mathpzc{L}$}
\put(70, 82){\line(1, 2){20}}
\pictext{90}{125}{$\mathpzc{L}$}
\pictext{55}{95}{1}
\pictext{85}{95}{2}

\pictext{140}{70}{$A$}
\put(140, 82){\circle*{4}}
\put(140, 82){\line(-1, 2){20}}
\pictext{120}{125}{$\mathpzc{L}$}
\put(140, 82){\line(1, 2){20}}
\pictext{160}{125}{$\mathpzc{W}$}
\pictext{115}{95}{1}
\pictext{155}{95}{2}

\pictext{210}{70}{$A$}
\put(210, 82){\circle*{4}}
\put(210, 82){\line(-1, 2){20}}
\pictext{190}{125}{$\mathpzc{L}$}
\put(210, 82){\line(1, 2){20}}
\pictext{230}{125}{$\mathpzc{W}$}
\pictext{195}{95}{1}
\pictext{225}{95}{2}

\pictext{280}{70}{$A$}
\put(280, 82){\circle*{4}}
\put(280, 82){\line(-1, 2){20}}
\pictext{260}{125}{$\mathpzc{W}$}
\put(280, 82){\line(1, 2){20}}
\pictext{300}{125}{$\mathpzc{L}$}
\pictext{265}{95}{1}
\pictext{295}{95}{2}


\end{picture}
\end{center}
\caption{\citegame{Five}}
\label{FiveGameChart}
\end{figure}

To read what's going on here, start at the node that isn't filled in, which in this case is the node at the bottom of the tree. The first move is made by $A$. She chooses to play either 1 or 2. If she plays 1, we go to the left of the chart, and now $B$ has a choice. She plays either 1 or 2, and now again $A$ has a choice. As it turns out, $A$ has the same choice to make whatever $B$ does, though there is nothing essential to this. This is just a two-player game, though there is also nothing essential to this. We could easily have let it be the case that a third player moved at this point. Or we could have made it that who moved at this point depended on which move $B$ had made. The extensive form representation allows for a lot of flexibility in this respect.

At the top of the diagram is a record of who won. In the more general form, we would put the payoffs to each player here. But when we have a simple zero-sum game, it is easier to just record the payoffs to one player. You should check that the description of who wins and loses in each situation is right. In each case, $A$ wins if 2 is played twice, and 1 once.

The extensive form representation form is very convenient for turn taking games. But you might think that it is much less convenient for games where players move simultaneously, as in Prisoners' Dilemma. But it turns out that we can represent that as well, through a small notational innovation. Figure \ref{PDEForm} is the game tree for Prisoners' Dilemma.

\begin{figure}[ht]
\begin{center}
\begin{picture}(350, 110)
\pictext{175}{0}{P1}
\put(175, 12){\circle{4}}\put(173, 13){\line(-2, 1){69}}
\put(177, 13){\line(2, 1){69}}
\pictext{135}{20}{A}
\pictext{215}{20}{B}

\pictext{105}{35}{P2}
\put(105, 47){\circle*{4}}
\put(105, 47){\line(-1, 1){35}}
\pictext{70}{85}{(1, 1)}
\put(105, 47){\line(1, 1){35}}
\pictext{140}{85}{(5, 0)}
\pictext{80}{55}{A}
\pictext{130}{55}{B}

\pictext{245}{35}{P2}
\put(245, 47){\circle*{4}}
\put(245, 47){\line(-1, 1){35}}
\pictext{210}{85}{(0, 5)}
\put(245, 47){\line(1, 1){35}}
\pictext{280}{85}{(3, 3)}
\pictext{220}{55}{A}
\pictext{270}{55}{B}

\multiput(105,47)(5, 0){28}{\line(1, 0){3}}

\end{picture}
\end{center}
\caption{Prisoners' Dilemma}
\label{PDEForm}
\end{figure}

\noindent The crucial thing here is the dashed line between the two nodes where P2 (short for Player 2) moves. What this means is that P2 doesn't know which of these nodes she is at when she moves. We normally assume that a player knows what moves are available to her. (Interesting philosophical question, which hasn't been much explored: What happens when we drop this assumption?) So we normally only put this kind of dashed line in when it connects two nodes at which the same player moves, and the available moves are the same. When we put in notation like this, we say that the nodes that are connected form an \textbf{information set}. If we don't mark anything, we assume that a node is in a degenerate information set, one that only contains itself.

Strictly speaking, you could regard this tree as a representation of a game where Player 1 goes first, then Player 2 moves, but Player 2 does not know Player 1's move when she moves. But that would be reading, I think, too much into the symbolic representation. What's crucial is that we can represent simultaneous move games in extensive form.\footnote{There is a philosophical assumption in this notational convention that we might want to come back to later on. It is usual to use dashed lines, like I've done, or circles or ovals to represent that for all Player 2 knows, she is at one of the connected nodes. But drawing circles around a set of possibilities is only a good way to represent Player 2's uncertainty if we assume quite a lot about knowledge. In particular, it is only good if we assume that which nodes are epistemically open for Player 2 is independent of which node, within that group, she is at. In formal terms, it amounts to assuming that knowledge is an S5 modality. This isn't actually a true assumption, and it makes for some interesting complications to game theory if we drop it. But for now we'll follow orthodoxy and assume we can use representaions like these dashed lines to represent uncertainty.}

These representations using graphs are knows as \textbf{extensive form} representations of games. The represenations using tables that we've used previously are known as \textbf{normal form} or \textbf{strategic form} representations. The idea is that any game really can be represented as game of one simultaneous move. The `moves' the players make are the selections of \textbf{strategies}. A strategy in this sense is a plan for what to do in any circumstance whatsoever.

Let's do this for the \citegame{Five}. A strategy for $A$ has three variables. It must specify what she does at the first move, what she does at the second move if $B$ plays 1, and what she does at the second move if $B$ plays 2.\footnote{We're assuming here that $A$ will play what she decides to play at the first move. It's possible to drop that assumption, but it results in much more complexity.} So we'll describe $A$'s strategy as $\alpha \beta \gamma$, where $\alpha$ is her move to begin with, $\beta$ is what she does if $B$ plays 1, and $\gamma$ is what she does if $B$ plays 2.  A strategy for $B$ needs to only have two variables: what to do if $A$ plays 1, and what to do if $A$ plays 2. So we'll notate her strategy as $\delta \epsilon$, where $\delta$ is what she does if $A$ plays 1, and $\epsilon$ is what she does if $A$ plays 2. So $A$ has 8 possible strategies, and $B$ has 4 possible strategies. Let's record the giant table listing the outcomes if thye play each of those strategies.

\starttab{r c c c c}
\textbf{\citegame{Five}} & 11 & 12 & 21 & 22 \\
111 & $\mathpzc{L}$ & $\mathpzc{L}$ &  $\mathpzc{L}$ & $\mathpzc{L}$\\
112 & $\mathpzc{L}$ & $\mathpzc{L}$ &  $\mathpzc{W}$ & $\mathpzc{W}$\\
121 & $\mathpzc{L}$ & $\mathpzc{L}$ &  $\mathpzc{L}$ & $\mathpzc{L}$\\
122 & $\mathpzc{L}$ & $\mathpzc{L}$ &  $\mathpzc{W}$ & $\mathpzc{W}$\\
211 & $\mathpzc{L}$ & $\mathpzc{W}$ &  $\mathpzc{L}$ & $\mathpzc{W}$\\
212 & $\mathpzc{L}$ & $\mathpzc{L}$ &  $\mathpzc{L}$ & $\mathpzc{L}$\\
221 & $\mathpzc{W}$ & $\mathpzc{W}$ &  $\mathpzc{W}$ & $\mathpzc{W}$\\
222 & $\mathpzc{W}$ & $\mathpzc{L}$ &  $\mathpzc{W}$ & $\mathpzc{L}$\\
\fintab

\noindent There is something quite dramatic about this representation. We can see what $A$ should play. If her strategy is 221, then whatever strategy $B$ plays, $A$ wins. So she should play that; it is a (weakly) dominant strategy. This isn't completely obvious from the extended form graph. 

Here's a related fact. Note that there are only 8 outcomes of the extended form game, but 32 cells in the table. Each outcome on the tree is represented by multiple cells of the table. Let's say we changed the game so that it finishes in a draw, represented by $\mathpzc{D}$, if the numbers picked sum to 3. That just requires changing one thing on the graph; the $\mathpzc{L}$ in the top-left corner has to be changed to a $\mathpzc{D}$. But it requires making many changes to the table.

\starttab{r c c c c}
\textbf{\citegame{Five}}$^\prime$ & 11 & 12 & 21 & 22 \\
111 & $\mathpzc{D}$ & $\mathpzc{D}$ &  $\mathpzc{L}$ & $\mathpzc{L}$\\
112 & $\mathpzc{D}$ & $\mathpzc{D}$ &  $\mathpzc{W}$ & $\mathpzc{W}$\\
121 & $\mathpzc{L}$ & $\mathpzc{L}$ &  $\mathpzc{L}$ & $\mathpzc{L}$\\
122 & $\mathpzc{L}$ & $\mathpzc{L}$ &  $\mathpzc{W}$ & $\mathpzc{W}$\\
211 & $\mathpzc{L}$ & $\mathpzc{W}$ &  $\mathpzc{L}$ & $\mathpzc{W}$\\
212 & $\mathpzc{L}$ & $\mathpzc{L}$ &  $\mathpzc{L}$ & $\mathpzc{L}$\\
221 & $\mathpzc{W}$ & $\mathpzc{W}$ &  $\mathpzc{W}$ & $\mathpzc{W}$\\
222 & $\mathpzc{W}$ & $\mathpzc{L}$ &  $\mathpzc{W}$ & $\mathpzc{L}$\\
\fintab

\noindent In part because of this fact, i.e., because every change to the value assignment in the extensive form requires making many changes in the values on the normal form, it isn't a coincidence that there's a row containing nothing but $\mathpzc{W}$. The following claim about our game can be proved.

\begin{quote}
Assign $\mathpzc{W}$ and $\mathpzc{L}$ in any way you like to the eight outcomes of the extended form game. Then draw the table that is the normal form representation of the game. It will either have a row containing nothing but $\mathpzc{W}$, i.e., a winning strategy for $A$, or a column containing nothing but $\mathpzc{L}$, i.e., a winning strategy for $B$.
\end{quote}

\noindent We will prove this in the next section, but first we will look at how to `solve' games like \citegame{Five}.

\section{Backwards Induction}

The way to think through games like \citegame{Five} is by working from top to bottom. $A$ moves last. Once we get to the point of the last move, there is no tactical decision making needed. $A$ knows what payoff she gets from each move, and she simply will take the highest payoff (assuming she is rational).

So let's assume she does that. Let's assume, that is, that $A$ does play her best strategy. Then we know three things about what will happen in the game.

\begin{itemize*}
\item If $A$ plays 1, and $B$ plays 2, $A$ will follow with 2.
\item If $A$ plays 2, and $B$ plays 1, $A$ will follow with 2.
\item If $A$ plays 2, and $B$ plays 2, $A$ will follow with 1.
\end{itemize*}

\noindent Moreover, once we make this assumption there is, in effect, one fewer step in the game. Once $B$ moves, the outcome is determined. So let's redraw the game using that assumption, and just listing payoffs after the second move. This will be Figure \ref{FiveGameChartSecondVersion}

\begin{figure}[ht]
\begin{center}
\begin{picture}(350, 100)
\pictext{175}{0}{$A$}
\put(175, 12){\circle{4}}\put(173, 13){\line(-2, 1){69}}
\put(177, 13){\line(2, 1){69}}
\pictext{135}{20}{1}
\pictext{215}{20}{2}

\pictext{105}{35}{$B$}
\put(105, 47){\circle*{4}}
\put(105, 47){\line(-1, 1){35}}
\put(105, 47){\line(1, 1){35}}
\pictext{80}{55}{1}
\pictext{70}{85}{$\mathpzc{L}$}
\pictext{130}{55}{2}
\pictext{140}{85}{$\mathpzc{W}$}

\pictext{245}{35}{$B$}
\put(245, 47){\circle*{4}}
\put(245, 47){\line(-1, 1){35}}
\pictext{210}{85}{$\mathpzc{W}$}
\put(245, 47){\line(1, 1){35}}
\pictext{280}{85}{$\mathpzc{W}$}
\pictext{220}{55}{1}
\pictext{270}{55}{2}

\end{picture}
\end{center}
\caption{\citegame{Five} with last move assumed}
\label{FiveGameChartSecondVersion}
\end{figure}

Now we can make the same assumption about $B$. Assume that $B$ will simply make her best move in this (reduced) game. Since $B$ wins if $A$ loses, $B$'s best move is to get to $\mathpzc{L}$. This assumption then, gives us just one extra constraint.

\begin{itemize*}
\item If $A$ plays 1, $B$ will follow with 1.
\end{itemize*}

\noindent And, once again, we can replace $B$'s actual movement with a payoff of the game under the assumption that $B$ makes the rational move. This gives us an even simpler representation of the game that we see in Figure \ref{FiveGameChartThirdVersion}.

\begin{figure}[ht]
\begin{center}
\begin{picture}(350, 65)
\put(175, 12){\circle{4}}\pictext{175}{0}{$A$}
\put(173, 13){\line(-2, 1){69}}
\pictext{105}{50}{$\mathpzc{L}$}
\put(177, 13){\line(2, 1){69}}
\pictext{245}{50}{$\mathpzc{W}$}
\pictext{135}{20}{1}
\pictext{215}{20}{2}

\end{picture}
\end{center}
\caption{\citegame{Five} with last two moves assumed}
\label{FiveGameChartThirdVersion}
\end{figure}

\pagebreak[1]
And from this version of the game, we can draw two more conclusions, assuming $A$ is rational.

\begin{itemize*}
\item $A$ will play 2 at the first move.
\item $A$ will win.
\end{itemize*}

\noindent Let's put all of that together. We know $A$ will start with 2, so her strategy will be of the form $2 \beta \gamma$. We also know that $B$ doesn't care which strategy she chooses at that point, so we can't make any further reductions. But we do know that if $A$ plays 2 and $B$ plays 1, $A$ will follow with 2. So $A$'s strategy will be of the form $2 2 \gamma$. And we know that if $A$ plays 2 and $B$ plays 2, then $A$ will play 1. So $A$'s strategy will be 221, as we saw on the table.

Note that, as in \citegame{Averages}, the use of backwards induction here hides a multitude of assumptions. We have to assume each player is rational, and each player knows that, and each player knows that, and so on for at least as many iterations as there are steps in the game. If we didn't have those assumptions, it wouldn't be right to simply replace a huge tree with a single outcome. Moreover, we have to make those assumptions be very modally robust. That is, we have to assume that they stay as assumptions no matter what else changes on the chart.

We can see this with a slight variant of the game. Let's say this time that the left two outcomes are $\mathpzc{D}$. So the graph looks like Figure \ref{RevisedFiveGameChart}.

\begin{figure}[ht]
\begin{center}
\begin{picture}(350, 150)
\pictext{175}{0}{$A$}
\put(175, 12){\circle{4}}\put(173, 13){\line(-2, 1){69}}
\put(177, 13){\line(2, 1){69}}
\pictext{135}{20}{1}
\pictext{215}{20}{2}

\pictext{105}{35}{$B$}
\put(105, 47){\circle*{4}}
\put(105, 47){\line(-1, 1){35}}
\put(105, 47){\line(1, 1){35}}
\pictext{80}{55}{1}
\pictext{130}{55}{2}

\pictext{245}{35}{$B$}
\put(245, 47){\circle*{4}}
\put(245, 47){\line(-1, 1){35}}
\put(245, 47){\line(1, 1){35}}
\pictext{220}{55}{1}
\pictext{270}{55}{2}

\pictext{70}{70}{$A$}
\put(70, 82){\circle*{4}}
\put(70, 82){\line(-1, 2){20}}
\pictext{50}{125}{$\mathpzc{D}$}
\put(70, 82){\line(1, 2){20}}
\pictext{90}{125}{$\mathpzc{D}$}
\pictext{55}{95}{1}
\pictext{85}{95}{2}

\pictext{140}{70}{$A$}
\put(140, 82){\circle*{4}}
\put(140, 82){\line(-1, 2){20}}
\pictext{120}{125}{$\mathpzc{L}$}
\put(140, 82){\line(1, 2){20}}
\pictext{160}{125}{$\mathpzc{W}$}
\pictext{115}{95}{1}
\pictext{155}{95}{2}

\pictext{210}{70}{$A$}
\put(210, 82){\circle*{4}}
\put(210, 82){\line(-1, 2){20}}
\pictext{190}{125}{$\mathpzc{L}$}
\put(210, 82){\line(1, 2){20}}
\pictext{230}{125}{$\mathpzc{W}$}
\pictext{195}{95}{1}
\pictext{225}{95}{2}

\pictext{280}{70}{$A$}
\put(280, 82){\circle*{4}}
\put(280, 82){\line(-1, 2){20}}
\pictext{260}{125}{$\mathpzc{W}$}
\put(280, 82){\line(1, 2){20}}
\pictext{300}{125}{$\mathpzc{L}$}
\pictext{265}{95}{1}
\pictext{295}{95}{2}


\end{picture}
\end{center}
\caption{\citegame{Five}$^{\prime \prime}$}
\label{RevisedFiveGameChart}
\end{figure}

Now we assume that $A$ makes the optimal move at the last step, so we can replace the top row of outcomes with the outcome that would happen if $A$ moves optimally. This gets us Figure \ref{RevisedFiveGameChartReduced}.

\begin{figure}[ht]
\begin{center}
\begin{picture}(350, 100)
\pictext{175}{0}{$A$}
\put(175, 12){\circle{4}}\put(173, 13){\line(-2, 1){69}}
\put(177, 13){\line(2, 1){69}}
\pictext{135}{20}{1}
\pictext{215}{20}{2}

\pictext{105}{35}{$B$}
\put(105, 47){\circle*{4}}
\put(105, 47){\line(-1, 1){35}}
\put(105, 47){\line(1, 1){35}}
\pictext{80}{55}{1}
\pictext{70}{85}{$\mathpzc{D}$}
\pictext{130}{55}{2}
\pictext{140}{85}{$\mathpzc{W}$}

\pictext{245}{35}{$B$}
\put(245, 47){\circle*{4}}
\put(245, 47){\line(-1, 1){35}}
\pictext{210}{85}{$\mathpzc{W}$}
\put(245, 47){\line(1, 1){35}}
\pictext{280}{85}{$\mathpzc{W}$}
\pictext{220}{55}{1}
\pictext{270}{55}{2}

\end{picture}
\end{center}
\caption{\citegame{Five}$^{\prime \prime}$ with last move assumed}
\label{RevisedFiveGameChartReduced}
\end{figure}

Now assume that $A$ plays 1 on the first round, so it is $B$'s turn to move. From \ref{RevisedFiveGameChartReduced} it looks like $B$ has an easy choice to make. If she plays 1, she gets a draw, if she plays 2, then $A$ wins, i.e., she loses. Since drawing is better than losing, she should play 1 and take the draw.

But why think that playing 2 will lead to $A$ winning? The argument that it did depending on assuming $A$ is perfectly rational. And assuming $B$ is in a position to make this choice, that seems like an unlikely assumption. After all, if $A$ were perfectly rational, she'd have chosen 2, and given herself a chance to force a win. 

Now you might think that even if $A$ isn't perfectly rational, it still is crazy to leave her with an easy winning move. And that's probably a sufficient reason for $B$ to accept the draw, i.e., play 1. But the argument that $B$ should regard playing 2 as equivalent to choosing defeat seems mistaken. $B$ knows that $A$ isn't perfectly rational, and she shouldn't assume perfect rationality from here on out.

We will come back to this point, a lot, in subsequent discussions of backwards induction. Note that it is a point that doesn't really arise in the context of normal form games. There we might wonder about whether common knowledge of rationality is a legitimate assumption at the \textit{start} of the game. But once we've settled that, we don't have a further issue to decide about whether it is still a legitimate assumption at later stages of the game.

\section{Value of Games}

Consider games with the following characteristics.

\begin{itemize*}
\item $A$ and $B$ take turns making moves. We will call each point at which they make a move, or at which the game ends, a \textbf{node} of the game.
\item At each move, each player knows what moves have been previously made.
\item At each move, the players have only finitely many possible moves open.
\item The players' preferences over the outcomes are opposite to one another. So if $A$ prefers outcome $o_1$ to $o_2$, then $B$ prefers $o_2$ to $o_1$, and if $A$ is indifferent between $o_1$ and $o_2$, then $B$ is indifferent between them as well.
\item $A$'s preferences over the outcomes are complete; for any two outcomes, she either prefers the first, or prefers the second, or is indifferent between them.
\item There is a known finite limit to the total number of possible moves in the game.
\end{itemize*}

\noindent The finiteness assumptions entail that there are only finitely many possible outcomes. So we can order the outcomes by $A$'s preferences. (Strictly speaking, we want to order sets of outcomes that are equivalence classes with respect to the relation that $A$ is indifferent between them.) Assign the outcome $A$ least prefers the value 0, the next outcome the value 1, and so on.

Now we recursively define the \textbf{value} of a node as follows.

\begin{itemize*}
\item The value of a \textbf{terminal node}, i.e., a node at which the game ends, is the payoff at that node.
\item The value of any node at which $A$ makes a choice is the greatest value of the nodes between which $A$ is choosing to move to.
\item The value of any node at which $B$ makes a choice is the least value of the nodes between which $B$ is choosing to move to.
\end{itemize*}

\noindent Finally, we say that the value of the game is the value of the initial node, i.e., the node at which the first choice is made. We can prove a number of things about the value of games. The proof will make crucial use of the notion of a \textbf{subgame}. In any extensive form game, a \textbf{subgame} of a game is the game we get by treating any perfect information node as the initial node of a game, and including the rest of the game `downstream' from there. 

By a perfect information node, I mean a node such that when it is reached, it is common knowledge that it is reached. That's true of all the nodes in most of the games we're looking at, but it isn't true in, for instance, the extensive form version of Prisoners' Dilemma we looked at. Nodes that are in non-degenerate information sets, i.e., information sets that contain other nodes, can't trigger subgames. That's because we typically assume that to play a game, players have to know what game they are playing.

Note that a subgame is really a game, just like a subset is a set. Once we're in the subgame, it doesn't matter a lot how we got there. Indeed, any game we represent is the consequence of some choices by the agent; they are all subgames of the game of life.

\stratcomp{The value of a game is the value of one of the terminal nodes}{We prove this by induction on the length of games. (The length of a game is the \textit{maximum} number of moves needed to reach a terminal node. We've only looked so far at games where every path takes the same number of moves to reach a conclusion, but that's not a compulsory feature of games.) 

If the game has zero moves, then it has just one node, and its value is the value of that node. And that node is a terminal node, so the value is the value of a terminal node. 

Now assume that the claim is true for any game of length $k$ or less, and consider an arbitrary game of length $k + 1$ The first node of the game consists of a choice about which path to go down. So the value of the initial node is the value of one of the subsequent nodes. Once that choice is made, we are in a subgame of length $k$, no matter which choice is made. By the inductive hypothesis, the value of that subgame is the value of one of its terminal nodes. So the value of the game, which is the value of one of the immediate subsequent nodes to the initial node, is the value of one of its terminal nodes. 
}

\stratcomp{$A$ can guarantee that the outcome of the game is at least the value of the game.}{
Again, we prove this by induction on the length of games. It is trivial for games of length 0. So assume it is true for all games of length at most $k$, and we'll prove it for games of length $k+1$. The initial node of such a game is either a move by $A$ or a move by $B$. We will consider these two cases separately.

Assume that $A$ makes the first move. Then the value of the initial node is the maximum value of any immediate successor node. So $A$ can select to go to the node with the same value as the value of the game. Then we're in a subgame of length $k$. By the inductive assumption, in that game $A$ can guarantee that the outcome is at least the value of the subgame. And since the value of that node is the value of the subgame, so it is also the value of the initial node, i.e., the value of the initial game. So by choosing that node, and starting that subgame, $A$ can guarantee that the outcome is at least the value of the game.

Now assume that $B$ makes the first move. $B$ can choose the node with the least value of the available choices. Then, as above, we'll be in a subgame in which (by the inductive hypothesis) $B$ can guarantee has an outcome which is at most its value. That is, $B$ can guarantee the outcome of the game is at most the value of the initial node of the subgame. And since $B$ can guarantee that that subgame is played, $B$ can guarantee that the game has an outcome of at most its value.}

\stratcomp{$B$ can guarantee that the outcome of the game is at most the value of the game.}{
The proof of this exactly parallels the previous proof, and the details are left as an exercise.}

\noindent Let's note a couple of consequences of these theorems.

First, assume that the rationality of each player is common knowledge, and that it is also common knowledge that this will persist throughout the game. Then the kind of backwards induction argument we used is discussing \citegame{Five} will show that the outcome of the game will be the value of the game. That's because if $A$ is rational and knows this much about $B$, the outcome won't be lower than the value, and if $B$ is rational and knows this much about $A$, the outcome won't be greater than the value.

Second, these theorems have many applications to real-life games. Both chess and checkers, for instance, satisfy the conditions we listed. The only condition that is not immediately obvious in each case is that the game ends in finite time. But the rules for draws in each game guarantee that is true.\footnote{Exercise: Prove this!} Since these games end with White win, Black win or draw, the value of the game must be one of those three outcomes.

In the case of checkers, we know what the value of the game is. It is a draw. This was proved by the Chinook project at the University of Alberta. We don't yet know what the value of chess is, but it is probably also a draw. Given how many possible moves there are in chess, and in principle how long games can go on, it is hard to believe that chess will be `solved' any time soon. But advances in chess computers may be able to justify to everyone's satisfaction a particular solution, even if we can't prove that is the value of chess.
